# ICU Monitor Vital Signs Extraction using Deep Learning

![ICU Monitor](https://your-image-link-if-needed) <!-- optional: insert an image or demo gif -->

## ğŸ“Œ Project Overview

This project presents a deep learning-based pipeline to **automatically extract vital signs** â€” such as **Heart Rate (HR)**, **Blood Pressure (BP)**, and **Oxygen Saturation (SpOâ‚‚)** â€” from ICU monitor images. The system combines **EfficientNet** for monitor detection and **PaddleOCR** for text recognition, enabling near real-time, accurate, and automated ICU data interpretation.

---

## âš™ï¸ Architecture

### ğŸ”¹ 1. Monitor Segmentation  
- **Model**: EfficientNet-B4  
- **Purpose**: Detect and localize ICU monitor screens from full-scene images  
- **Accuracy**: IOU score of **94â€“96%**  
- **Preprocessing**: Padding, skew correction, resizing, and cropping to improve accuracy

### ğŸ”¹ 2. Text Detection & Mapping  
- **Tool**: PaddleOCR  
- **Logic**: Geometric layout analysis and keyword-based nearest-number association  
- **Accuracy**: 88â€“92% OCR accuracy on real ICU images  

---

## ğŸ§  Vital Sign Detection Logic

- **Heart Rate (HR)**: Detected via "HR" keyword or green text mask if keyword fails  
- **SpOâ‚‚ & RR**: Identified through positional and keyword proximity logic  
- **Blood Pressure (SBP/DBP) & MAP**: Handled via `/` separation, bounding boxes, and keyword mapping  
- **ECG Detection**: Green contour isolation; fallback to `neurokit2` simulation if undetected

---

## ğŸ§ª Dataset & Training

- **Type**: Mixed dataset (real ICU scenes + synthetic augmentations)  
- **Augmentations**: Brightness, skew, rotation, Gaussian noise  
- **Environment**: Google Colab + Local RTX 3060 GPU  
- **Optimizer**: Adam, LR = 0.001, 50 epochs  

---

## ğŸ“ˆ Results

| Metric                  | Value        |
|------------------------|--------------|
| Segmentation IOU       | 94â€“96%       |
| OCR Text Accuracy      | 88â€“92%       |
| End-to-End Accuracy    | ~85%         |
| Execution Speed        | ~1 sec/frame |

---

## ğŸ” Observations

- **HR**: Typically green; appears in top 30% of screen  
- **SpOâ‚‚ & RR**: Inconsistent colors; detected with keywords + position heuristics  
- **BP**: SBP/DBP often separated by `/`; MAP often in brackets or nearby  
- **Challenges**: Lighting variance, layout inconsistency, text overlap, OCR misreads  

---

## ğŸš€ Future Enhancements

- Real-time video stream support  
- ECG waveform interpretation for arrhythmia detection  
- Multilingual OCR support  
- Integration with hospital IT systems for live alerts  

---

## ğŸ‘¨â€ğŸ’» Authors

- Brijesh Ahirwar  
- Dhanush Kamatam  
- Kushaan Mahajan  
- Gowtham Palli  
- **Supervisor**: Dr. Amritanshu Pandey, Department of Electronics Engineering, IIT (BHU)

---

## ğŸ“„ Citation

If you use this work, please consider citing or referencing our exploratory project under EC291, IIT (BHU) Varanasi.

---

## ğŸ—‚ï¸ Files Included

- `model/` â€“ Trained model checkpoints  
- `src/` â€“ Code for segmentation, OCR, and logic pipeline  
- `notebooks/` â€“ Jupyter notebooks for testing  
- `samples/` â€“ Example ICU monitor images  
- `results/` â€“ Output examples with vital signs  
- `README.md` â€“ Project overview

---

## ğŸ”— Resources

- [EfficientNet](https://arxiv.org/abs/1905.11946)  
- [PaddleOCR](https://github.com/PaddlePaddle/PaddleOCR)  
- [Neurokit2](https://neurokit2.readthedocs.io/en/latest/)

